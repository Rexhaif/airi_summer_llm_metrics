{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61c58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 08:34:01,063] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import AdamW, get_scheduler\n",
    "from transformers import pipeline\n",
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "\n",
    "from functools import partial\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab05736-d2ef-4a06-8a02-31e2107b90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    'q_proj',\n",
    "    'k_proj',\n",
    "    'v_proj',\n",
    "    'up_proj',\n",
    "    'down_proj'\n",
    "]\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MICRO_BATCH_SIZE = 32\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "OUTPUT_DIR = \"llama2_7b_finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d0fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    }
   ],
   "source": [
    "wmt_base = load_dataset('RicardoRei/wmt-da-human-evaluation', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df92ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = ['en-de', 'en-ru', 'zh-en']\n",
    "id2langs = {\n",
    "    'ru': 'russian',\n",
    "    'en': 'english',\n",
    "    'de': 'german',\n",
    "    'zh': 'chinese'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df69213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-1cfd06b39276352a.arrow\n",
      "Loading cached shuffled indices for dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-c80783202fc9a509.arrow\n",
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-9e804864585ee5cf.arrow\n",
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-a0338df62a22c4f9.arrow\n",
      "Loading cached shuffled indices for dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-cde3219d510a8791.arrow\n",
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-535e1cc14f9d4233.arrow\n",
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-e96e3dcb82ba4bee.arrow\n",
      "Loading cached shuffled indices for dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-926161d0dc32af45.arrow\n",
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-546c48c3b25f6946.arrow\n",
      "Loading cached shuffled indices for dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-7a2ec1c2a66e3109.arrow\n"
     ]
    }
   ],
   "source": [
    "train_take_part = 0.25\n",
    "eval_take_part = 0.1\n",
    "\n",
    "train_dataset = []\n",
    "eval_dataset = []\n",
    "\n",
    "for translation in translations:\n",
    "    train_part = wmt_base.filter(lambda example: (example['year'] != 2022) & (example['lp'] == translation))\n",
    "    train_part = train_part.shuffle(seed=42)\n",
    "    train_dataset.append(Dataset.from_dict(train_part[:int(len(train_part)*train_take_part)]))\n",
    "\n",
    "    eval_part = wmt_base.filter(lambda example: (example['year'] == 2022) & (example['lp'] == translation))\n",
    "    eval_part = eval_part.shuffle(seed=42)\n",
    "    eval_dataset.append(Dataset.from_dict(eval_part[:int(len(eval_part)*eval_take_part)]))\n",
    "train_dataset = concatenate_datasets(train_dataset)\n",
    "eval_dataset = concatenate_datasets(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334e9006-c1b7-4b43-bc02-63aaf5e78a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return ' '.join(text.lower().strip().split())\n",
    "\n",
    "def get_gemba_da_prompt(langs, source_seg, reference_seg, target_seg, score=None):\n",
    "    src_lang_id, tgt_lang_id = langs.split('-')\n",
    "    source_lang, target_lang = id2langs[src_lang_id], id2langs[tgt_lang_id]\n",
    "    source_seg, reference_seg, target_seg = map(preprocess, [source_seg, reference_seg, target_seg])\n",
    "    return ''.join([f'Score the following translation from {source_lang} to {target_lang} respect to the human reference on a continuous scale from 0 to 100, ',\n",
    "            'where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\n',\n",
    "            f'{source_lang} source: \"{source_seg}\"\\n',\n",
    "            f'{target_lang} human reference: \"{reference_seg}\"\\n',\n",
    "            f'{target_lang} translation: \"{target_seg}\"\\n',\n",
    "            'Score:' if score is None else f'Score: {score}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e126e47-ea0f-4cb3-bf72-b5d808b638ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['lp', 'src', 'mt', 'ref', 'score', 'raw', 'annotators', 'domain', 'year'],\n",
       "        num_rows: 90281\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['lp', 'src', 'mt', 'ref', 'score', 'raw', 'annotators', 'domain', 'year'],\n",
       "        num_rows: 2082\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_datasets = DatasetDict({'train': train_dataset, 'eval': eval_dataset})\n",
    "wmt_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58d417f-6bb3-4b5c-b916-d315b6257f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_tokenizer = AutoTokenizer.from_pretrained('./llama-2-7b-hf/')\n",
    "llama2_tokenizer.pad_token = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f685e2-7414-4d90-bac6-1bd19f3aba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_translation(data, tokenizer, prompt_func, fields, max_length=MAX_LENGTH, inference=False):\n",
    "    prompt = prompt_func(*[data[field] for field in fields])\n",
    "    result = tokenizer(prompt, truncation=True, max_length=max_length, padding=False)\n",
    "    if result['input_ids'][-1] != tokenizer.eos_token_id \\\n",
    "        and len(result['input_ids']) < max_length:\n",
    "        result['input_ids'].append(tokenizer.eos_token_id)\n",
    "        result['attention_mask'].append(1)\n",
    "    if not inference:\n",
    "        result['labels'] = result['input_ids'].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1989a9d-4055-4af5-a7b6-99f53c238016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/90281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama2_wmt_finetune_datasets = wmt_datasets.map(partial(tokenize_translation,\n",
    "                                                        tokenizer=llama2_tokenizer,\n",
    "                                                        prompt_func=get_gemba_da_prompt,\n",
    "                                                        fields=['lp', 'src', 'ref', 'mt', 'raw']),\n",
    "                                                num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ead0d0-3758-4d84-b4ae-b8f7eb8474d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask', 'labels']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_wmt_finetune_datasets = llama2_wmt_finetune_datasets.remove_columns(set(llama2_wmt_finetune_datasets['train'].column_names)-{'input_ids', 'attention_mask', 'labels'})\n",
    "llama2_wmt_finetune_datasets.set_format('torch')\n",
    "llama2_wmt_finetune_datasets['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc0121c-8318-4219-95fd-4396c9bc1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    llama2_tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b29df64-ce89-4aa4-8336-b54c5079bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    llama2_wmt_finetune_datasets['train'], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    llama2_wmt_finetune_datasets['eval'], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc8c1be-703c-49bb-bca3-f9a72efacd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 256]),\n",
       " 'attention_mask': torch.Size([8, 256]),\n",
       " 'labels': torch.Size([8, 256])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c4db760-635a-4bc7-99bd-bcd25aeebff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d38e8de32454d04bb344beb94b361b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('./llama-2-7b-hf/', device_map='auto',\n",
    "                                             torch_dtype=torch.float16, load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2404d24-e2f7-4a32-b16c-e32743e951ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 28,049,408 || all params: 6,766,465,024 || trainable%: 0.4145356238525057\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5025e5cc-5182-44b0-b681-fc680797fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text):\n",
    "    score = re.search('Score: \\d+(\\.\\d+)?|$', text).group(0).split(' ', 1)[-1]\n",
    "    if score.replace('.', '').isnumeric:\n",
    "        return float(score)\n",
    "    return -1.0\n",
    "\n",
    "def compute_metrics(eval_data, tokenizer):\n",
    "    preds, labels = eval_data\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    pred_scores = []\n",
    "    label_scores = []\n",
    "    skips = 0\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        label = get_score(label)\n",
    "        if label < 0:\n",
    "            skips += 1\n",
    "            continue\n",
    "        pred = get_score(pred)\n",
    "        pred_scores.append(pred)\n",
    "        label_scores.append(label)\n",
    "\n",
    "    r = spearmanr(pred_scores, label_scores)\n",
    "    tau = kendalltau(pred_scores, label_scores)\n",
    "    return {'R': r.statistic, 'tau': tau.statistic, 'skip_for_eval': skips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82e1cb1-49d7-414b-9006-3168ec50a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./llama2_7b_finetune\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=MICRO_BATCH_SIZE,\n",
    "    logging_steps=20,\n",
    "    warmup_steps=100,\n",
    "    save_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    weight_decay=1e-6,\n",
    "    eval_steps=400,\n",
    "    save_steps=400,\n",
    "    save_total_limit=3,\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=None,\n",
    "    optim='adamw_torch',\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=int(MAX_LENGTH*3/2)\n",
    ")\n",
    "\n",
    "trainer = transformers.Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=llama2_tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=llama2_wmt_finetune_datasets['train'],\n",
    "    eval_dataset=llama2_wmt_finetune_datasets['eval'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=partial(compute_metrics, tokenizer=llama2_tokenizer)\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(\n",
    "        self, old_state_dict()\n",
    "    )\n",
    ").__get__(model, type(model))\n",
    " \n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf25ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mw-vskv-w\u001b[0m (\u001b[33mairi23-efficient-llm-metrics\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vyskov/Effective_Metrics/wandb/run-20230724_083531-82bgt9wz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/airi23-efficient-llm-metrics/huggingface/runs/82bgt9wz' target=\"_blank\">whole-leaf-23</a></strong> to <a href='https://wandb.ai/airi23-efficient-llm-metrics/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/airi23-efficient-llm-metrics/huggingface' target=\"_blank\">https://wandb.ai/airi23-efficient-llm-metrics/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/airi23-efficient-llm-metrics/huggingface/runs/82bgt9wz' target=\"_blank\">https://wandb.ai/airi23-efficient-llm-metrics/huggingface/runs/82bgt9wz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vyskov/miniconda3/envs/py3.10/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='1411' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/1411 01:11 < 14:00:17, 0.03 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3d74e-5097-4a88-b6ef-0e8609991641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./llama2_7b_wmt_finetune_lora_qkv_updown_proj_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ad5bf-3544-41aa-9fc1-d12948a5e8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee490059-eb04-4294-b017-8223bf48c76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-750e7e0241e2fef2.arrow\n"
     ]
    }
   ],
   "source": [
    "test_dataset = wmt_base.filter(lambda example: (example['year'] == 2022) & (example['lp'] in translations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9705a07a-b5a4-4e04-88a3-dc5958e0015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vyskov/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-da-human-evaluation-a4a96cd6106c3667/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-750e7e0241e2fef2.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/20820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_dataset = test_dataset.map(partial(tokenize_translation,\n",
    "                                        tokenizer=llama2_tokenizer,\n",
    "                                        prompt_func=get_gemba_da_prompt,\n",
    "                                        max_length=MAX_LENGTH*2,\n",
    "                                        fields=['lp', 'src', 'ref', 'mt'],\n",
    "                                        inference=True),\n",
    "                                num_proc=4)\n",
    "labels = test_dataset['raw']\n",
    "\n",
    "test_dataset = test_dataset.remove_columns(set(test_dataset.column_names)-{'input_ids', 'attention_mask'})\n",
    "test_dataset.set_format('torch')\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, shuffle=False, batch_size=16, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "160a3622-6f39-46d0-90a8-fb41655c2b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'generated_text': 'Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"按照先试点再推行，由点到面逐步推进的原则，探索建立校企联合招生、联合培养、一体化育人的长效机制，切实提升学生岗位技能，提高学生对口就业率和就业质量。\"\\nen human reference: \"According to the principle of experimental units first and implementation later, and gradual advancement from point to area, the long-term mechanism of joint recruitment by schools and enterprises, joint training and integrated training shall be explored and established, so as to fundamentally improve the job skills of students and improve the rate of employment fitting students’ major, as well as the quality of employment quality of students.\"\\nen translation: \"In accordance with the principle of piloting first and then implementing it, and gradually advancing from point to point, we will explore the establishment of a long-term mechanism for joint enrollment, joint training, and integrated education of schools and enterprises, so as to effectively improve students\\' job skills and improve the employment rate and quality of their counterparts.\"\\nScore: 99.9999999999999999999999999999999999999999999999999999999999'}],\n",
       " 76.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 14535\n",
    "pipeline('text-generation', model=model, tokenizer=llama2_tokenizer, device_map='auto', torch_dtype=torch.float16)(get_gemba_da_prompt(\n",
    "    test_dataset[i]['lp'], test_dataset[i]['src'], test_dataset[i]['ref'], test_dataset[i]['mt']), max_length=400), test_dataset[i]['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7ee6c-1cf0-47b2-b268-b7466ec20888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a115cac-fda9-48e7-b466-c45d42c57861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29900, 29900, 29900,  ..., 18120, 29915, 29879],\n",
      "        [29900, 29900, 29900,  ..., 18120, 29915, 29879],\n",
      "        [29900, 29900, 29900,  ...,   474, 29915, 29885],\n",
      "        ...,\n",
      "        [29900, 29900, 29900,  ...,   474, 29915, 29885],\n",
      "        [29900, 29900, 29900,  ...,  7013,  2039,    13],\n",
      "        [    1,  2522,   487,  ...,  1213,    13, 20097]])\n",
      "['000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"是否有途径处罚他\"\\nen human reference: \"Is there a way to punish him?\"\\nen translation: \"Is there a way to punish him\"\\nScore: nobody\\'s business but the lord\\'s', '00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"以免再次发生这样的事情\"\\nen human reference: \"So that such a thing won’t happen again.\"\\nen translation: \"lest it happen again\"\\nScore: nobody\\'s business but the lord\\'s', '00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"又或者餐厅还要多久会准备好？可不可以帮我问下？\"\\nen human reference: \"And how much longer does it take for the restaurant to prepare it? Could could help me ask them?\"\\nen translation: \"Or how long before the restaurant will be ready? Could you help me ask?\"\\nScore: nobody\\'s perfect, but i\\'m', '00000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"浙大学术年会上学生唱主角 研究成果让人脑洞大开-新华网\"\\nen human reference: \"Students played the leading role at the Annual Academic Conference of Zhejiang University with creative research achievements - Xinhuanet\"\\nen translation: \"Students singing leading roles at the Zhejiang University Academic Conference research achievements make people\\'s brains open - Xinhua\"\\nScore: nobody\\'s perfect, but i\\'m', 'Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"用空气来洗手，哈口气判断疾病，精确搜寻雾霾来源 昨天晚上，在浙江大学2016年学术年会开幕式上，一系列脑洞大开的学术成果获得表彰。\"\\nen human reference: \"Washing hands with air, diagnosing disease through breath, and accurately seeking for source of smog; last night, a series of creative academic achievements were awarded at the opening ceremony of the 2016 Annual Academic Conference of Zhejiang University.\"\\nen translation: \"Wash hands with air, judge diseases with tone, and search for the source of haze Precisely Last night, a series of creative academic achievements', 'Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"这些成果的主要研究者都是学生，研究覆盖了环境、机械、能源、医疗、生命科学、人文教育等各大领域，同学们从一个好奇的点子开始，创造出了许多具有应用价值的高端发明，其中一些项目已在国内国际获奖。\"\\nen human reference: \"The main researchers of these achievements are students, with research covering major fields of environment, machinery, energy, medicine, life science and humanities education; students created many high-end inventions with application values from a curious idea, and some of them have won awards at home and abroad.\"\\nen translation: \"These achievements are mainly researched', '000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"生物传感器：你的家庭体检医生\"\\nen human reference: \"Biosensor: your home physical examination doctor\"\\nen translation: \"Biosensors: Your home medical examiner\"\\nScore: nobody\\'s business but the lord\\'s', '00000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"生物医学工程学院博士生张迪鸣团队现场展示了一个智能手机端的生物传感器，大小只有智能手机的一半。\"\\nen human reference: \"The team of Zhang Diming, a doctoral student of School of Biomedical Engineering, showed a biosensor on the smart phone with the size of only a half of a smart phone.\"\\nen translation: \"The team of Zhang Di Ming, a doctoral student in the School of Biomedical Engineering, showed a biosensor on the side of a smartphone, half the size of a smartphone.\"\\nScore: #1000Speak for Com', '000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"“你只需要轻轻呼一口气，这套仪器就能从你呼出的气体成分中，初步检测身体健康状况 。 ”\"\\nen human reference: \"“All you need to do is to breathe out, and this set of instrument can detect your physical conditions preliminarily from the components of the air you breathe out.”\"\\nen translation: \"\"All you need to do is breathe lightly. This set of instruments can initially detect your health from the gas composition you\\'re exhaling.\"\"\\nScore: nobody\\'s perfect, but i\\'m', '00000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"张迪鸣介绍说，这套传感器与智能手机相连，呼出气体后，健康报告就会显示在手机上。\"\\nen human reference: \"Zhang Diming introduced, this set of sensor is connected to the smart phone; after you breathe out, the health report will be shown on your phone.\"\\nen translation: \"Zhang Di Ming said that this set of sensors is connected to the smartphone, and after exhaling the gas, the health report will be displayed on the phone.\"\\nScore: #1000Speak for Com', '000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"市场上能够检测健康状况的智能手环，一般检测的是温度、脉搏等物理参数。\"\\nen human reference: \"Smart bands on the market which can detect health conditions often measure physical parameters such as temperature and pulse.\"\\nen translation: \"Smart bracelets that can detect health conditions on the market generally detect temperature, pulse and other physical parameters.\"\\nScore: nobody\\'s perfect, but i\\'m', 'Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"而这套生物传感器运用了石墨烯这种新型材料，它的目标物是化学元素，敏锐的“嗅觉”让它能更深度、准确地体现身体健康状况。\"\\nen human reference: \"This set of biological sensor uses the new material of graphene; its target is chemical elements, and its keen “sense of smell” enables it to reflect the health status of the body more in-depth and accurately.\"\\nen translation: \"And this set of biosensors uses graphene as a new material. Its target is the chemical elements, and its keen \"sense of smell\" allows it to more deeply and accurately reflect the health of the body.\"\\nScore: #10000000', '00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"智能手术灯：医生的高能眼睛\"\\nen human reference: \"Smart operation lamp: high-functioning eyes for doctors\"\\nen translation: \"Smart operating lights: a doctor\\'s high-energy eye\"\\nScore: nobody\\'s perfect, but i\\'m', '00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"除了智能手机，手术室里也用起了智能手术灯。\"\\nen human reference: \"In addition to smart phones, smart operation lamps are now being used in operating rooms.\"\\nen translation: \"In addition to smartphones, smart operating lights are also used in the operating room.\"\\nScore: nobody\\'s perfect, but i\\'m', '00000000000000000000000000000000000000000000000000000000000000000000000000000000000000 Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"这项发明在今年第44届瑞士日内瓦国际发明展中获得银奖。\"\\nen human reference: \"This invention has won the silver prize in the 44th International Exhibition of Inventions in Geneva, Switzerland this year.\"\\nen translation: \"This invention won the silver prize at the 44th International Invention Exhibition in Geneva, Switzerland this year.\"\\nScore: nobody\\'s business but the turks\\n', 'Score the following translation from zh to en respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"光电科学与工程学院硕士生朱林靖、申俊飞团队在传统手术灯的缺陷中开启了新思路，发明了智能LED手术无影灯。\"\\nen human reference: \"The team of Zhu Linjing and Shen Junfei, two graduate students from School of Optoelectronic Science and Engineering, developed a new idea trying to solve the defects of traditional operating lamps and invented the smart LED operation shadow-less lamp.\"\\nen translation: \"Zhu Linjing, a master\\'s student in the School of Optoelectronic Science and Engineering, and the team of Shin Junfei opened new ideas in the defects of traditional surgical lights, and invented smart LED surgical shadow-less lamps.\"\\nScore']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        output = model.generate(**batch, max_new_tokens=10)\n",
    "        print(output)\n",
    "        print(llama2_tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a9de9-1bd2-447a-8a45-26f2ad785af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513b0d1-e6fc-48a7-b22b-781c16abfec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
