{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272b6b05-0f42-4130-8af1-d32c3326a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, MT5EncoderModel\n",
    "from transformers.modeling_outputs import BaseModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6382d84f-b8aa-4b1e-b94e-39f64c6004c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder_name = \"bigscience/mt0-base\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10322c7e-174d-42a9-9127-372bab5312b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc3e975-1bd7-4e8f-a6b4-59ef301eae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b37197-9ae0-4fbd-8154-2ee335db375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Regressor(nn.Module):\n",
    "    def __init__(self, checkpoint, sizes_mlp, act=nn.Tanh):\n",
    "        super(T5Regressor, self).__init__()\n",
    "\n",
    "        self.llm = MT5EncoderModel.from_pretrained(\n",
    "            checkpoint, output_attentions=True, output_hidden_states=True\n",
    "        )\n",
    "\n",
    "        self.llm_output_shape = sizes_mlp[0]\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(sizes_mlp) - 1):\n",
    "            layers.append(nn.Linear(sizes_mlp[i], sizes_mlp[i + 1]))\n",
    "            # layers.append(lora.Linear(sizes_mlp[i], sizes_mlp[i + 1], r=16))\n",
    "            if i < len(sizes_mlp) - 2:\n",
    "                layers.append(act())\n",
    "\n",
    "        layers.append(nn.Dropout(0.1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Sigmoid()\n",
    "\n",
    "        self.loss_fc = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        # print(input_ids, attention_mask)\n",
    "        outputs = self.llm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = mean_pooling(\n",
    "            outputs.last_hidden_state, outputs.attentions[-1][:, 0, :, 0]\n",
    "        )\n",
    "        outputs_sequence = self.dropout(embeddings)\n",
    "\n",
    "        logits = self.output_layer(self.mlp(outputs_sequence)) * 100\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fc(logits.view(-1, 1), labels.view(-1).unsqueeze(1))\n",
    "\n",
    "        return (\n",
    "            BaseModelOutput(\n",
    "                last_hidden_state=outputs.last_hidden_state,\n",
    "                hidden_states=outputs.hidden_states,\n",
    "                attentions=outputs.attentions,\n",
    "            ),\n",
    "            logits,\n",
    "            loss,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4da57d-605b-49ad-8a5a-d0a2b0c745af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5Regressor(checkpoint=model_encoder_name, sizes_mlp=[768, 192, 48, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbcb0d4-7378-451d-98b3-17653fbc70e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"checkpoints/model_arc_5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1810eed3-6dc9-45be-8efe-b639779a3fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Regressor(\n",
       "  (llm): MT5EncoderModel(\n",
       "    (shared): Embedding(250112, 768)\n",
       "    (encoder): MT5Stack(\n",
       "      (embed_tokens): Embedding(250112, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-11): 11 x MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): MT5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=192, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=192, out_features=48, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=48, out_features=1, bias=True)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (output_layer): Sigmoid()\n",
       "  (loss_fc): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb45f8-509d-421f-8301-e070ace1884b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33405fef-9c2f-4047-9113-d7f4ac117905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/jovyan/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-mqm-human-evaluation-13a9a3b878e9c5ea/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['lp', 'src', 'mt', 'ref', 'score', 'system', 'annotators', 'domain', 'year'],\n",
       "    num_rows: 150347\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"RicardoRei/wmt-mqm-human-evaluation\", split=\"train\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0061a80b-dae2-47cc-a925-ad79245ea8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/RicardoRei___csv/RicardoRei--wmt-mqm-human-evaluation-13a9a3b878e9c5ea/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-792642c7a8b42625.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['lp', 'src', 'mt', 'ref', 'score', 'system', 'annotators', 'domain', 'year'],\n",
       "    num_rows: 67575\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = dataset.filter(\n",
    "    lambda example: (example[\"year\"] == 2022)\n",
    "    and (\n",
    "        (example[\"lp\"] == \"en-ru\")\n",
    "        or (example[\"lp\"] == \"zh-en\")\n",
    "        or (example[\"lp\"] == \"en-de\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4074ba78-a2e7-470d-9d6e-355794976059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67575/67575 [00:07<00:00, 9434.03it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt_column = []\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Score the following translation from {source_lang} to {target_lang} with respect to the human reference on a continuous scale from 0 to 100, where score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\n",
    "{source_lang} source: \"{source_seg}\"\n",
    "{target_lang} human reference: {reference_seg}\n",
    "{target_lang} translation: \"{target_seg}\"\n",
    "Score:\n",
    "\"\"\"\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "    example = dataset_test[i]\n",
    "    sl, tl = example[\"lp\"].split(\"-\")\n",
    "    prompt_column.append(\n",
    "        prompt_template.format(\n",
    "            source_lang=sl,\n",
    "            target_lang=tl,\n",
    "            source_seg=example[\"src\"],\n",
    "            reference_seg=example[\"ref\"],\n",
    "            target_seg=example[\"mt\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a497f232-0706-41f5-be68-59efb4f73412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/67575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = dataset_test.add_column(name=\"prompt\", column=prompt_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87f4f0ba-3d16-4027-bb26-6585018cedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lp': 'zh-en',\n",
       " 'src': '用了一段时间，质量不错，屏幕分辨率也很清晰。',\n",
       " 'mt': 'Been using it for a while and the quality is nice and the screen resolution is crystal clear.',\n",
       " 'ref': 'I’ve used it for some time; it is of high quality, with clear screen resolution.',\n",
       " 'score': -1.0,\n",
       " 'system': 'comet_bestmbr',\n",
       " 'annotators': 1,\n",
       " 'domain': 'ecommerce',\n",
       " 'year': 2022,\n",
       " 'prompt': '\\nScore the following translation from zh to en with respect to the human reference on a continuous scale from 0 to 100, where score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\\nzh source: \"用了一段时间，质量不错，屏幕分辨率也很清晰。\"\\nen human reference: I’ve used it for some time; it is of high quality, with clear screen resolution.\\nen translation: \"Been using it for a while and the quality is nice and the screen resolution is crystal clear.\"\\nScore:\\n'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[41152]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6470e3-8824-407e-98a6-2b2bce712351",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1510779-2956-4503-ab45-0103bd6c3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f375b9-e653-49e0-8317-0719a1a37dda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "604cef6f-6ae3-40ac-9912-01d5822d2774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_tokenized = dataset_test.map(\n",
    "    lambda example: tokenizer(\n",
    "        example[\"prompt\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    ),\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6895942a-6f2c-473d-adac-1cd5c2b9d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/67575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_tokenized.save_to_disk(\"wmt-mqm_tokenized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2971c17-c4e0-4ff2-83bc-297e05d1818f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6889fe-37cf-4c25-a993-7d3aa92f0a3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19efa249-00cb-4b51-a175-a1addb127477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = load_from_disk(\"wmt-mqm_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce94c6a-d893-4e14-a7d0-87027b7125b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['lp', 'src', 'mt', 'ref', 'score', 'system', 'annotators', 'domain', 'year', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 67575\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029ec544-3506-4b74-9960-696f455d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = dataset_tokenized.with_format(\"torch\").remove_columns(\n",
    "    [\"lp\", \"src\", \"mt\", \"ref\", \"annotators\", \"domain\", \"year\", \"prompt\", \"system\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b7c2586-82aa-41fe-9dcb-573b9212f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e148b003-5ff1-4819-93ca-fdd52123c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(dataset_tokenized[\"score\"].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76fde28b-d99f-4464-8459-3c731d4fd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = dataset_tokenized.add_column(\n",
    "    column=scaler.transform(dataset_tokenized[\"score\"].reshape(-1, 1)).reshape(1, -1)[\n",
    "        0\n",
    "    ],\n",
    "    name=\"labels\",\n",
    ").remove_columns([\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec4c4f-0763-473b-83f0-6114e22e4d4f",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89d3bb35-4e53-4c45-b8b9-b7c16f260968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67575/67575 [15:03<00:00, 74.77it/s] \n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "predicted = []\n",
    "\n",
    "for batch in tqdm(dataset_tokenized):\n",
    "    batch = {k: v.to(device).reshape(1, -1) for k, v in batch.items()}\n",
    "\n",
    "    labels.append(batch[\"labels\"][0][0].item())\n",
    "    with torch.no_grad():\n",
    "        predicted.append(model(**batch)[1][0][0].item() / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79bedcd-9920-4356-9083-aaf42a715b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26220868683714754"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kendalltau(predicted, labels)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
