{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69be262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2931247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223599b",
   "metadata": {},
   "source": [
    "## Прикручиваем LaBSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7afbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fbb27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3832fcba5640a8be2efc0857b2a6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0fe39/.gitattributes:   0%|          | 0.00/968 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a887d3ba2f4baba36bb0e6630ea4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342e2cec01d541b1a63b0dee1fd3e3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)83e900fe39/README.md:   0%|          | 0.00/3.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af041563b4a4e379ba3684711d1cafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e900fe39/config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4087e12f374d8e9e29f94322eba08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b1b531fd024875ab65eb6479708b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663e90becafa40d5b83f590223ee5bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83160de0ab44537a0e3b9d6abfd2504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6004931004452b86236aba698e694a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5afb65b88e409794fdf34432474b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f163dce3bc477faca1b066703d2d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153fdad3c47a446493d9b4947f852e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading unigram.json:   0%|          | 0.00/14.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3352db72f3dd4165a844f4f5f3fe316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)900fe39/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-27 17:20:25,028] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "LaBSE_name = 'sentence-transformers/LaBSE'\n",
    "LaBSE_small_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "sentence_model = SentenceTransformer(LaBSE_small_name)\n",
    "embeddings = sentence_model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772ecd8",
   "metadata": {},
   "source": [
    "## Учим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5521097",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import ParallelSentencesDataset, losses\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8057c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6256b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your fine-tuning task\n",
    "dataset = load_dataset(\"RicardoRei/wmt-da-human-evaluation\",split=\"train\")\n",
    "train_dataset = dataset.filter(lambda example: (example[\"year\"] == 2022) & (example[\"lp\"] in [\"en-ru\", \"zh-en\", \"en-de\"]))\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8189f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigscience/mt0-small\"\n",
    "# checkpoint = \"bigscience/mt0-base\"\n",
    "# checkpoint = \"bigscience/mt0-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, torch_dtype=\"auto\")\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08adc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del pipe\n",
    "except NameError:\n",
    "    pass\n",
    "pipe = pipeline(\"text2text-generation\",\n",
    "                model=checkpoint,\n",
    "                device=\"cpu\",\n",
    "                tokenizer=tokenizer\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gimba_prompt(source_lang, source_seg, target_lang, target_seg):\n",
    "    return f'''Score the following translation from {source_lang} to {target_lang} with respect to the human reference on a continuous scale from 0 to 100, where a score of zero means \"no meaning preserved\" and score of one hundred means \"perfect meaning and grammar\".\n",
    "    {source_lang} source: \"{source_seg}\"\n",
    "    {target_lang} human reference: {reference_seg}\n",
    "    {target_lang} translation: \"{target_seg}\"\n",
    "    Score:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95df19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED += 1\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 5\n",
    "\n",
    "import re\n",
    "score_values_2 = []\n",
    "for item in train_dataset:\n",
    "    source_lang, target_lang = item['lp'].split('-')\n",
    "    source_seg = item['src']\n",
    "    reference_seg = item['mt']\n",
    "    target_seg = item['ref']\n",
    "    prompt = get_gimba_prompt(source_lang, source_seg, target_lang, target_seg)\n",
    "    try:\n",
    "        data_list = pipe(prompt, temperature=0.15)\n",
    "        for item in data_list:\n",
    "            generated_text = item['generated_text']\n",
    "            \n",
    "            print(\"generated_text\", generated_text)\n",
    "            print(\"item generated text:\", item[\"generated_text\"], \" ;\")\n",
    "            print(\"score str:\", generated_text, \" ;\")\n",
    "            \n",
    "            score_match = re.search(r'\\d+(\\.\\d+)?', generated_text)\n",
    "            if score_match:\n",
    "                score = float(score_match.group())\n",
    "                score_values_2.append(score)\n",
    "            else:\n",
    "                print(f\"Ошибка: не удалось извлечь число из строки '{score_str}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке данных: {e}\")\n",
    "    \n",
    "    print() # разделить вывод\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break # debug, to see only one scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb222d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c82fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
